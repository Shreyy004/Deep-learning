{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "457b6104-e16f-47a0-bcf9-e1c3df261aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a52b52b4-49cf-446c-b22d-8441c701be1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"C:/Users/HP/Downloads/archive (8)/train\"\n",
    "test_dir = \"C:/Users/HP/Downloads/archive (8)/test\"\n",
    "train_csv = \"Training_set.csv\"\n",
    "test_csv = \"Testing_set.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8203d490-5438-4a1b-a2e5-3d907c73dd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_csv)\n",
    "test_df = pd.read_csv(test_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcbacddc-df9b-49c9-a62a-9cb41fb7d246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure proper file paths\n",
    "train_df['filepath'] = train_df['filepath'].apply(lambda x: os.path.normpath(x))\n",
    "test_df['filepath'] = test_df['filepath'].apply(lambda x: os.path.normpath(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8620d1d-25ce-449c-86ab-c524d9d43107",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "train_df['label_encoded'] = label_encoder.fit_transform(train_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b23721b1-c168-49ae-aa87-171c398440bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128\n",
    "def load_images(df):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for _, row in df.iterrows():\n",
    "        img_path = row['filepath']\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE)) / 255.0  # Normalize\n",
    "        images.append(img)\n",
    "        labels.append(row['label_encoded'])\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c28e1f3a-a831-4fbd-8f96-accb4c76d91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      filename                     label  \\\n",
      "0  Image_1.jpg          SOUTHERN DOGFACE   \n",
      "1  Image_2.jpg                    ADONIS   \n",
      "2  Image_3.jpg            BROWN SIPROETA   \n",
      "3  Image_4.jpg                   MONARCH   \n",
      "4  Image_5.jpg  GREEN CELLED CATTLEHEART   \n",
      "\n",
      "                                            filepath  label_encoded  \n",
      "0  C:/Users/HP/Downloads/archive (8)/train\\Image_...             66  \n",
      "1  C:/Users/HP/Downloads/archive (8)/train\\Image_...              0  \n",
      "2  C:/Users/HP/Downloads/archive (8)/train\\Image_...             12  \n",
      "3  C:/Users/HP/Downloads/archive (8)/train\\Image_...             44  \n",
      "4  C:/Users/HP/Downloads/archive (8)/train\\Image_...             33  \n"
     ]
    }
   ],
   "source": [
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc79ad34-60fa-4c7c-972e-b35efa3f959a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ee0cac-45bd-45d2-91cc-5c65461588cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define paths\n",
    "train_dir = \"path/to/train/\"\n",
    "test_dir = \"path/to/test/\"\n",
    "train_csv = \"path/to/Training_set.csv\"\n",
    "test_csv = \"path/to/Testing_set.csv\"\n",
    "\n",
    "# Load CSV files\n",
    "train_df = pd.read_csv(train_csv)\n",
    "test_df = pd.read_csv(test_csv)\n",
    "\n",
    "# Extract file names and labels (Assuming 'label' column exists)\n",
    "train_df['filepath'] = train_dir + train_df['filename']\n",
    "test_df['filepath'] = test_dir + test_df['filename']\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_df['label_encoded'] = label_encoder.fit_transform(train_df['label'])\n",
    "\n",
    "# Load and preprocess images\n",
    "IMG_SIZE = 128\n",
    "\n",
    "def load_images(df):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for _, row in df.iterrows():\n",
    "        img_path = row['filepath']\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE)) / 255.0  # Normalize\n",
    "        images.append(img)\n",
    "        labels.append(row['label_encoded'])\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_train, y_train = load_images(train_df)\n",
    "X_test, y_test = load_images(test_df)\n",
    "\n",
    "# Train-validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=42)\n",
    "\n",
    "# Convert labels to categorical\n",
    "num_classes = len(label_encoder.classes_)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# CNN Model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=30,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "# Evaluate on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"\\nTest accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=label_encoder.classes_))\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
